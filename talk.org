#+title: Can machines learn to program?
#+AUTHOR: Federico Mon
#+EMAIL: gnu.fede@gmail.com
#+DATE: 2016-10-08
#+OPTIONS: num:nil toc:nil todo:nil
#+REVEAL_ROOT: ./reveal.js/
# #+REVEAL_ROOT: https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.2.0/
#+REVEAL_EXTRA_CSS: ./custom.css
#+REVEAL_SLIDE_NUMBER: nil
#+REVEAL_THEME: white
#+REVEAL_TRANS: linear
# #+REVEAL_BACKGROUND: #272822

* 
   :PROPERTIES:
   :reveal_background: #f2600f
   :END:
   #+NAME:   fig:ticketea
   [[./img/logo-ticketea-white.svg]]


* TDD

** 
#+BEGIN_SRC python
def test_sort(self):
    my_list = [4, 3, 2, 0]
    my_list.sort()
    self.assertEqual(my_list, [0, 2, 3, 4])
#+END_SRC

** 
#+BEGIN_SRC python
class myList(list):
    def sort(self):
        return self.reverse()
__builtins__.list = myList

def test_sort(self):
    my_list = list((4, 3, 2, 0))
    my_list.sort()
    self.assertEqual(my_list, list((0, 2, 3, 4)))
#+END_SRC

** Program testing can be used to show the presence of bugs, but never to show their absence!
Edgar Dijkstra

* Can machines do TDD?
* A very small example
** Basic Multiplexor
#+NAME:   fig:NO
[[./img/Multiplexer.png]]

** 
#+BEGIN_SRC bash
A B Sel | Out
-------------
0 0   0 |   0
0 0   1 |   0
0 1   0 |   0
0 1   1 |   1
1 0   0 |   1
1 0   1 |   0
1 1   0 |   1
1 1   1 |   1 
#+END_SRC
** 
#+BEGIN_SRC python
(a and not s) or (b and s)
#+END_SRC
** AST
#+NAME:   fig:AST_multi
[[./img/multiplexer_ast.png]]
** 
#+NAME:   fig:prefix_notation
[[./img/prefix_notation.png]]
** Prefix notation
  OR AND A NOT S AND B S
* AST
** 
#+BEGIN_SRC python
>>> import ast
>>> tree = ast.parse("(a and not s) or (b and s)")
>>> expr = ast.Expression(tree.body[0].value)
>>> compiled = compile(expr, filename="<ast>", mode="eval")
>>> a = True
>>> b = False
>>> s = True
>>> d = eval(compiled)
>>> print(d)
#+END_SRC
#+BEGIN_SRC python
False
#+END_SRC
** 
#+BEGIN_SRC python
>>> import meta
>>> source_from_ast = meta.dump_python_source(tree)
#+END_SRC
#+BEGIN_SRC python
((a and (not s)) or (b and s))
#+END_SRC
** 
#+BEGIN_SRC python
from ast import (
    BoolOp, UnaryOp, Or, And, Not, Name, Load, Module, Expr,
    NodeTransformer, NodeVisitor, copy_location, Subscript, Index, Str, dump
)
#+END_SRC
** Visitor and Transformer
*** 
#+BEGIN_SRC python
class Visitor(NodeVisitor):
    length = 0

    def generic_visit(self, node):
        self.length += 1
        NodeVisitor.generic_visit(self, node)
#+END_SRC
*** 
#+BEGIN_SRC python
def get_len(tree):
    v = Visitor()
    v.visit(tree)
    return v.length
#+END_SRC
* Genetic Programming
** Individuals
 #+ATTR_REVEAL: :frag (appear)
 * Each one has its own DNA
 * In nature: "...GATTACA..."
 * In Genetic Algorithms, it can be "...0010100..."
 * In our case, let's say it's: "OR AND A NOT S AND B S"
 * So, why not simply the python AST?
#+BEGIN_NOTES
  * Notación Polaca
#+END_NOTES
** As Genetic Algorithms
 #+ATTR_REVEAL: :frag (appear)
 * Start with a population
 * Evaluate them
 * Select some individuals
 * Mix them
 * Mutate them
 * Repeat
** Evaluation
 #+ATTR_REVEAL: :frag (appear)
 * In our case, how many unit tests the program passes
 * For our multiplexor, there are only 8 unit tests

** Mix them
You would need to extract two parts of two trees and interchange them.
** 
#+NAME:   fig:Genetic Programming Mix
[[./img/genetic_mix.png]]

** Mutate them
*** 
#+NAME:   fig:Genetic Programming Mutation
[[./img/genetic_mutate.png]]
*** Transformer
*** 
#+BEGIN_SRC python
class Mutator(NodeTransformer):
    depth = 0

    def some_visit(self, node):
        if self.depth > 2 and random.randrange(9) > 5:
            return create_something(max_depth=3)
        else:
            self.generic_visit(node)
            return node

    def visit_Name(self, node):
        self.depth += 1
        return self.some_visit(node)

    def visit_UnaryOp(self, node):
        self.depth += 1
        return self.some_visit(node)

    def visit_BoolOp(self, node):
        self.depth += 1
        return self.some_visit(node)
#+END_SRC
*** 
#+BEGIN_SRC python
def mutate(tree):
    return Mutator().visit(tree)
#+END_SRC

* Neural Networks
** Mimics the brain
** Use lots of data as training to learn
** Input layer, hidden layers, output layer
** 
#+NAME:   fig:Neural network
[[./img/neural_network.jpg]]
** Hidden layers can be very complex, depending on your needs
** 
#+ATTR_REVEAL: :frag (appear)
#+NAME:   fig:a man is sorting his fruit at a fruit stand
[[./img/nn_ex3.jpg]]
 * a man is sorting his fruit at a fruit stand
** 
#+NAME:   fig:captioning_neural_network
[[./img/neural_network_image.jpg]]
** 
#+NAME:   fig:coder_neural_network
[[./img/neural_network_code.jpg]]
** Not Accomplished :(

* “When in doubt, use brute force”
Ken Thompson
** Is it any better than random?
#+ATTR_REVEAL: :frag (appear)
   * We should find out
   * Let's generate random trees until we reach our goal.
** 
  #+NAME:   fig:madness
  [[./img/madness.jpg]]
** Genetic programming results:
    #+ATTR_REVEAL: :frag (appear)
    * Population size 100: average: 3.51 secs
    * Population size 10: average: 4.63 secs
** Random trees:
    #+ATTR_REVEAL: :frag (appear)
    Average 100 executions: 3.40 secs
* Answer
** 
:PROPERTIES:
:reveal_background: #000000
:END:
#+NAME:   fig:NO
[[./img/no.png]]
** Not yet at least
** “In the discrete world of computing, there is no meaningful metric in which "small" changes and "small" effects go hand in hand, and there never will be.”
Edgar Dijkstra
** “Perfect is the enemy of good”
    #+ATTR_REVEAL: :frag (appear)
    Voltaire
** 
#+NAME:   fig:local maximum
[[./img/localmax.png]]
** Computers not yet capable to “reason”
** Programming requires “Divide and Conquer”
** How do we demonstrate the absence of bugs?
** What is being done?
*** Python interpreter in ML (Predicts the output of the program)
**** https://github.com/wojciechz/learning_to_execute
** Bibliography
 * [[https://docs.python.org/2/library/ast.html][Official AST documentation]]
 * [[http://greentreesnakes.readthedocs.io/en/latest/][Green Tree Snakes - the missing Python AST docs]]
 * DEAP: https://github.com/DEAP/deap
* To be continued...?
