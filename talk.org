#+title: Can machines learn to program?
#+AUTHOR: Federico Mon
#+EMAIL: gnu.fede@gmail.com
#+DATE: 2016-10-08
#+OPTIONS: num:nil toc:nil todo:nil
#+REVEAL_ROOT: ./reveal.js/
# #+REVEAL_ROOT: https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.2.0/
#+REVEAL_EXTRA_CSS: ./custom.css
#+REVEAL_SLIDE_NUMBER: nil
#+REVEAL_THEME: white
#+REVEAL_TRANS: linear
# #+REVEAL_BACKGROUND: #272822

* 
   :PROPERTIES:
   :reveal_background: #f2600f
   :END:
   #+NAME:   fig:ticketea
   [[./img/logo-ticketea-white.svg]]


* TODO First of all...
** What will you do once you automate all your work?
[[https://www.reddit.com/r/cscareerquestions/comments/4km3yc/finally_fired_after_6_years/][Finally fired after 6 years]]
#+NAME:   fig:Fired_after_6_years
[[./img/Automate.png]]

* TODO What is “To program”?
*** Source code
#+BEGIN_SRC python
def x(a, b, c):
    return (a + b) * c
#+END_SRC
*** Bytecode
#+BEGIN_SRC python
>>> x = lambda a,b,c: (a + b) * c
>>> x.__code__.co_code                                                                                                                             
b'|\x00\x00|\x01\x00\x17|\x02\x00\x14S'
#+END_SRC
*** AST
#+NAME:   fig:AST
[[./img/binop.png]]

* TDD

** 
#+BEGIN_SRC python
def test_sort(self):
    my_list = [4, 3, 2, 0]
    my_list.sort()
    self.assertEqual(my_list, [0, 2, 3, 4])
#+END_SRC

** 
#+BEGIN_SRC python
class myList(list):
    def sort(self):
        return self.reverse()
__builtins__.list = myList

def test_sort(self):
    my_list = list((4, 3, 2, 0))
    my_list.sort()
    self.assertEqual(my_list, list((0, 2, 3, 4)))
#+END_SRC

** TODO 
#+BEGIN_SRC python
def test_sort(self):
    my_list = list((3, 4, 2, 0))
    my_list.sort()
    self.assertEqual(my_list, list((0, 2, 3, 4)))
#+END_SRC

** TODO 
#+BEGIN_SRC python
class myList(list):
    def sort(self):
        x = list(self[-1], self[-2], self[0], self[1])
        self[0] = x[0]
        self[1] = x[1]
        self[2] = x[2]
        self[3] = x[3]
__builtins__.list = myList

def test_sort(self):
    my_list = list((3, 4, 2, 0))
    my_list.sort()
    self.assertEqual(my_list, list((0, 2, 3, 4)))
#+END_SRC
** Program testing can be used to show the presence of bugs, but never to show their absence!
Edgar Dijkstra

* TODO Lots of fuzz with Deep Learning lately
** Alphago
#+NAME:   fig:Alphagologo
[[./img/Alphago_logo_Reversed.svg]]

** Wired Cover Jun 2016
#+NAME:   fig:wiredcover2016
[[./img/wired_cover.png]]
#+BEGIN_NOTES
  * Portada de Wired de Junio de este año (2016)
  * Por lo que vemos en la portada, Wired debe haber conseguido generar portadas
    por ordenador antes o después de haber echado a su diseñador. no?
#+END_NOTES

* Can machines do TDD?
* A very small example
** Basic Multiplexor
#+NAME:   fig:NO
[[./img/Multiplexer.png]]

** 
#+BEGIN_SRC bash
A B Sel | Out
-------------
0 0   0 |   0
0 0   1 |   0
0 1   0 |   0
0 1   1 |   1
1 0   0 |   1
1 0   1 |   0
1 1   0 |   1
1 1   1 |   1 
#+END_SRC
** 
#+BEGIN_SRC python
(a and not s) or (b and s)
#+END_SRC
** AST
#+NAME:   fig:AST_multi
[[./img/multiplexer_ast.png]]
** 
#+NAME:   fig:prefix_notation
[[./img/prefix_notation.png]]
** Prefix notation
  OR AND A NOT S AND B S
* AST
** 
#+BEGIN_SRC python
>>> import ast
>>> tree = ast.parse("(a and not s) or (b and s)")
>>> expr = ast.Expression(tree.body[0].value)
>>> compiled = compile(expr, filename="<ast>", mode="eval")
>>> a = True
>>> b = False
>>> s = True
>>> d = eval(compiled)
>>> print(d)
#+END_SRC
#+BEGIN_SRC python
False
#+END_SRC
** 
#+BEGIN_SRC python
>>> import meta
>>> source_from_ast = meta.dump_python_source(tree)
#+END_SRC
#+BEGIN_SRC python
((a and (not s)) or (b and s))
#+END_SRC
** 
#+BEGIN_SRC python
from ast import (
    BoolOp, UnaryOp, Or, And, Not, Name, Load, Module, Expr,
    NodeTransformer, NodeVisitor, copy_location, Subscript, Index, Str, dump
)
#+END_SRC
** TODO 
#+BEGIN_SRC python
def create_variable(variable_name):
    assert variable_name in variable_names
    return Name(id=variable_name, ctx=Load())

def create_not(tree):
    return UnaryOp(op=Not(), operand=tree)

def create_or(args):
    assert len(args) > 1
    return BoolOp(Or(), args)
#+END_SRC
** Visitor and Transformer
*** 
#+BEGIN_SRC python
class Visitor(NodeVisitor):
    length = 0

    def generic_visit(self, node):
        self.length += 1
        NodeVisitor.generic_visit(self, node)
#+END_SRC
*** 
#+BEGIN_SRC python
def get_len(tree):
    v = Visitor()
    v.visit(tree)
    return v.length
#+END_SRC
* Genetic Programming
** Individuals
 #+ATTR_REVEAL: :frag (appear)
 * Each one has its own DNA
 * In nature: "...GATTACA..."
 * In Genetic Algorithms, it can be "...0010100..."
 * In our case, let's say it's: "OR AND A NOT S AND B S"
 * So, why not simply the python AST?
#+BEGIN_NOTES
  * Notación Polaca
#+END_NOTES
** As Genetic Algorithms
 #+ATTR_REVEAL: :frag (appear)
 * Start with a population
 * Evaluate them
 * Select some individuals
 * Mix them
 * Mutate them
 * Repeat
** Evaluation
 #+ATTR_REVEAL: :frag (appear)
 * In our case, how many unit tests the program passes
 * For our multiplexor, there are only 8 unit tests

** Mix them
You would need to extract two parts of two trees and interchange them.
** 
#+NAME:   fig:Genetic Programming Mix
[[./img/genetic_mix.png]]

** Mutate them
*** 
#+NAME:   fig:Genetic Programming Mutation
[[./img/genetic_mutate.png]]
*** Transformer
*** 
#+BEGIN_SRC python
class Mutator(NodeTransformer):
    depth = 0

    def some_visit(self, node):
        if self.depth > 2 and random.randrange(9) > 5:
            return create_something(max_depth=3)
        else:
            self.generic_visit(node)
            return node

    def visit_Name(self, node):
        self.depth += 1
        return self.some_visit(node)

    def visit_UnaryOp(self, node):
        self.depth += 1
        return self.some_visit(node)

    def visit_BoolOp(self, node):
        self.depth += 1
        return self.some_visit(node)
#+END_SRC
*** 
#+BEGIN_SRC python
def mutate(tree):
    return Mutator().visit(tree)
#+END_SRC

** Good news
*** DEAP
    https://github.com/DEAP/deap

* Neural Networks
** Mimics the brain
** Use lots of data as training to learn
** Input layer, hidden layers, output layer
** 
#+NAME:   fig:Neural network
[[./img/neural_network.jpg]]
** Hidden layers can be very complex, depending on your needs
** 
#+ATTR_REVEAL: :frag (appear)
#+NAME:   fig:a man is talking on a cell phone near a building
[[./img/nn_ex1.jpg]]
 * a man is talking on a cell phone near a building.
** 
#+ATTR_REVEAL: :frag (appear)
#+NAME:   fig:a white dog is running on gravel away from two people and a black and brown dog
[[./img/nn_ex2.jpg]]
 * a white dog is running on gravel away from two people and a black and brown dog.
** 
#+ATTR_REVEAL: :frag (appear)
#+NAME:   fig:a man is sorting his fruit at a fruit stand
[[./img/nn_ex3.jpg]]
 * a man is sorting his fruit at a fruit stand
** 
#+NAME:   fig:captioning_neural_network
[[./img/neural_network_image.jpg]]
** 
#+NAME:   fig:coder_neural_network
[[./img/neural_network_code.jpg]]
** Not Accomplished :(

* “When in doubt, use brute force”
Ken Thompson
** Is it any better than random?
#+ATTR_REVEAL: :frag (appear)
   * We should find out
   * Let's generate random trees until we reach our goal.
** 
  #+NAME:   fig:madness
  [[./img/madness.jpg]]
** Genetic programming results:
    #+ATTR_REVEAL: :frag (appear)
    * Population size 100: average: 3.51 secs
    * Population size 10: average: 4.63 secs
** Random trees:
    #+ATTR_REVEAL: :frag (appear)
    Average 100 executions: 3.40 secs
* Answer
** 
:PROPERTIES:
:reveal_background: #000000
:END:
#+NAME:   fig:NO
[[./img/no.png]]
** Not yet at least
** “In the discrete world of computing, there is no meaningful metric in which "small" changes and "small" effects go hand in hand, and there never will be.”
Edgar Dijkstra
** “Perfect is the enemy of good”
    #+ATTR_REVEAL: :frag (appear)
    Voltaire
** 
#+NAME:   fig:local maximum
[[./img/localmax.png]]
** Computers not yet capable to “reason”
** Programming requires “Divide and Conquer”
** That was just boolean logic
What about detecting infinite loops in huge programs?
** How do we demonstrate the absence of bugs?
** What is being done?
*** Python interpreter in ML (Predicts the output of the program)
**** https://github.com/wojciechz/learning_to_execute
** Bibliography
 * [[https://docs.python.org/2/library/ast.html][Official AST documentation]]
 * [[http://greentreesnakes.readthedocs.io/en/latest/][Green Tree Snakes - the missing Python AST docs]]
